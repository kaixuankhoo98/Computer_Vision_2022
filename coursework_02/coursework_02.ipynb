{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2: Fish Classification\n",
    "\n",
    "Created by Athanasios Vlontzos and Wenjia Bai\n",
    "\n",
    "In this coursework, you will be exploring the application of convolutional neural networks for image classification tasks. As opposed to standard applications such as object or face classification, we will be dealing with a slightly different domain, fish classification for precision fishing.\n",
    "\n",
    "In precision fishing, engineers and fishmen collaborate to extract a wide variety of information about the fish, their species and wellbeing etc. using data from satellite images to drones surveying the fisheries. The goal of precision fishing is to provide the marine industry with information to support their decision making processes.\n",
    "\n",
    "Here your will develop an image classification model that can classify fish species given input images. It consists of two tasks. The first task is to train a model for the following species:\n",
    "- Black Sea Sprat\n",
    "- Gilt-Head Bream\n",
    "- Shrimp\n",
    "- Striped Red Mullet\n",
    "- Trout\n",
    "\n",
    "The second task is to finetune the last layer of the trained model to adapt to some new species, including:\n",
    "- Hourse Mackerel\n",
    "- Red Mullet\n",
    "- Red Sea Bream\n",
    "- Sea Bass\n",
    "\n",
    "You will be working using a large-scale fish dataset [1].\n",
    "\n",
    "[1] O. Ulucan, D. Karakaya and M. Turkan. A large-scale dataset for fish segmentation and classification. Innovations in Intelligent Systems and Applications Conference (ASYU). 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Download data.\n",
    "\n",
    "[Download the Data from here -- make sure you access it with your Imperial account.](https://imperiallondon-my.sharepoint.com/:f:/g/personal/av2514_ic_ac_uk/EkA9HyXVvgdFoLI4P_IfO1cBO_CsvY1KN4NE8iuD-s_VlA?e=Ip03rF)\n",
    "\n",
    "It is a ~2.5GB file. You can save the images and annotations directories in the same directory as this notebook or somewhere else.\n",
    "\n",
    "The fish dataset contains 9 species of fishes. There are 1,000 images for each fish species, named as %05d.png in each subdirectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data. (15 Points)\n",
    "\n",
    "- Complete the dataset class with the skeleton below.\n",
    "- Add any transforms you feel are necessary.\n",
    "\n",
    "Your class should have at least 3 elements\n",
    "- An ```__init__``` function that sets up your class and all the necessary parameters.\n",
    "- An ```__len__``` function that returns the size of your dataset.\n",
    "- An ```__getitem__``` function that given an index within the limits of the size of the dataset returns the associated image and label in tensor form.\n",
    "\n",
    "You may add more helper functions if you want.\n",
    "\n",
    "In this section we are following the Pytorch [dataset](https://pytorch.org/vision/stable/datasets.html) class structure. You can take inspiration from their documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We will start by building a dataset class using the following 5 species of fishes\n",
    "Multiclass_labels_correspondances = {\n",
    "    'Black Sea Sprat': 0,\n",
    "    'Gilt-Head Bream': 1,\n",
    "    'Shrimp': 2,\n",
    "    'Striped Red Mullet': 3,\n",
    "    'Trout': 4\n",
    "}\n",
    "\n",
    "# The 5 species will contain 5,000 images in total.\n",
    "# Let us split the 5,000 images into training (80%) and test (20%) sets\n",
    "def split_train_test(lendata, percentage=0.8):\n",
    "    #### ADD YOUR CODE HERE ####\n",
    "    indexes = np.array(range(0,lendata))\n",
    "    np.random.shuffle(indexes)\n",
    "    train_size = int(lendata * percentage)\n",
    "    \n",
    "    idxs_train = indexes[:train_size]\n",
    "    idxs_test = indexes[train_size:]\n",
    "\n",
    "    return idxs_train, idxs_test\n",
    "\n",
    "LENDATA = 5000\n",
    "np.random.seed(42)\n",
    "idxs_train, idxs_test = split_train_test(LENDATA,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the dataset class\n",
    "class FishDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 path_to_images,\n",
    "                 idxs_train,\n",
    "                 idxs_test,\n",
    "                 transform_extra=None,\n",
    "                 img_size=128,\n",
    "                 train=True):\n",
    "        # path_to_images: where you put the fish dataset\n",
    "        # idxs_train: training set indexes\n",
    "        # idxs_test: test set indexes\n",
    "        # transform_extra: extra data transform\n",
    "        # img_size: resize all images to a standard size\n",
    "        # train: return training set or test set\n",
    "        \n",
    "        # Load all the images and their labels\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        inverted_labels = {v: k for k, v in Multiclass_labels_correspondances.items()} # invert the values and keys\n",
    "        self.filenames_all = []\n",
    "        self.file_labels = []\n",
    "        for value in inverted_labels:\n",
    "            self.filenames_all.extend(glob.glob(path_to_images + \"/\" + inverted_labels[value] + \"/*.png\"))\n",
    "            for i in range(len(glob.glob(path_to_images + \"/\" + inverted_labels[value] + \"/*.png\"))):\n",
    "                self.file_labels.append(value)\n",
    "        \n",
    "        # Resize all images to a standard size\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        resize = transforms.Compose([transforms.Resize((img_size,img_size))]) # rezize image before storing in array\n",
    "    \n",
    "        self._set = []\n",
    "        self._labels = []\n",
    "        if train:\n",
    "            self._idxs = idxs_train\n",
    "        else:\n",
    "            self._idxs = idxs_test\n",
    "        \n",
    "        self.transform = transforms.ToTensor()\n",
    "        for index in self._idxs:\n",
    "            # train_set contains list of tensors\n",
    "            img = resize(Image.open(self.filenames_all[index]))\n",
    "            img_tensor = self.transform(img)\n",
    "            self._set.append(img_tensor)\n",
    "            # train labels contains list of labels\n",
    "            self._labels.append(self.file_labels[index])\n",
    "        # stack the images into a 4D tensor\n",
    "        self.train_set = torch.stack(self._set)\n",
    "#         for index in idxs_test:\n",
    "#             # test_set contains list of tensors\n",
    "#             img = resize(Image.open(self.filenames_all[index]))\n",
    "#             img_tensor = img_tensor = self.transform(img)\n",
    "#             self.test_set.append(img_tensor)\n",
    "#             # test labels contains list of labels\n",
    "#             self.test_labels.append(self.file_labels[index])\n",
    "#         # stack the images into a 4D tensor\n",
    "#         self.test_set = torch.stack(self.test_set)\n",
    "           \n",
    "        # Extract the images and labels with the specified file indexes      \n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return the number of samples\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        return self._idxs.size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Get an item using its index\n",
    "        '''\n",
    "        Returns (image,label)\n",
    "        '''\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        return (self._set[idx], self._labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore the data. (15 Points)\n",
    "\n",
    "### Step 2.1: Data visualisation. (5 points)\n",
    "\n",
    "- Plot data distribution, i.e. the number of samples per class.\n",
    "- Plot 1 sample from each of the five classes in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training set\n",
    "img_path = './Fish_Dataset' # changed to path on my local machine\n",
    "dataset  = FishDataset(img_path, idxs_train, idxs_test, None, img_size=128, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = FishDataset(img_path, idxs_train, idxs_test, None, img_size=128, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "Number of 'Black Sea Sprat' samples\n",
      "811\n",
      "Number of 'Gilt-Head Bream' samples\n",
      "809\n",
      "Number of 'Shrimp' samples\n",
      "787\n",
      "Number of 'Striped Red Mullet' samples\n",
      "796\n",
      "Number of 'Trout' samples\n",
      "797\n",
      "\n",
      "Test set:\n",
      "Number of 'Black Sea Sprat' samples\n",
      "189\n",
      "Number of 'Gilt-Head Bream' samples\n",
      "191\n",
      "Number of 'Shrimp' samples\n",
      "213\n",
      "Number of 'Striped Red Mullet' samples\n",
      "204\n",
      "Number of 'Trout' samples\n",
      "203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of classes in test set')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_number_of_samples(data, cls):\n",
    "    return data.count(cls)\n",
    "\n",
    "# Plot the number of samples per class\n",
    "#### ADD YOUR CODE HERE ####\n",
    "print(\"Train set:\")\n",
    "print(\"Number of 'Black Sea Sprat' samples\")\n",
    "print(get_number_of_samples(dataset._labels, 0))\n",
    "print(\"Number of 'Gilt-Head Bream' samples\")\n",
    "print(get_number_of_samples(dataset._labels, 1))\n",
    "print(\"Number of 'Shrimp' samples\")\n",
    "print(get_number_of_samples(dataset._labels, 2))\n",
    "print(\"Number of 'Striped Red Mullet' samples\")\n",
    "print(get_number_of_samples(dataset._labels, 3))\n",
    "print(\"Number of 'Trout' samples\")\n",
    "print(get_number_of_samples(dataset._labels, 4))\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(\"Number of 'Black Sea Sprat' samples\")\n",
    "print(get_number_of_samples(test_set._labels, 0))\n",
    "print(\"Number of 'Gilt-Head Bream' samples\")\n",
    "print(get_number_of_samples(test_set._labels, 1))\n",
    "print(\"Number of 'Shrimp' samples\")\n",
    "print(get_number_of_samples(test_set._labels, 2))\n",
    "print(\"Number of 'Striped Red Mullet' samples\")\n",
    "print(get_number_of_samples(test_set._labels, 3))\n",
    "print(\"Number of 'Trout' samples\")\n",
    "print(get_number_of_samples(test_set._labels, 4))\n",
    "\n",
    "classes = np.array([0,1,2,3,4])\n",
    "train_distribution = []\n",
    "for i in range(5):\n",
    "    train_distribution.append(get_number_of_samples(dataset._labels, i))\n",
    "train_distribution = np.array(train_distribution)\n",
    "test_distribution = []\n",
    "for i in range(5):\n",
    "    test_distribution.append(get_number_of_samples(test_set._labels, i))\n",
    "test_distribution = np.array(test_distribution)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15,7))\n",
    "ax1.bar(classes, train_distribution)\n",
    "ax1.set_title(\"Distribution of classes in train set\")\n",
    "ax2.bar(classes, test_distribution)\n",
    "ax2.set_title(\"Distribution of classes in test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dac1cd3c10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot 1 sample from each of the five classes in the training set\n",
    "#### ADD YOUR CODE HERE ####\n",
    "image_sprat = dataset.__getitem__(4)\n",
    "image_bream = dataset.__getitem__(0)\n",
    "image_shrimp = dataset.__getitem__(2)\n",
    "image_mullet = dataset.__getitem__(1)\n",
    "image_trout = dataset.__getitem__(12)\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5)\n",
    "fig.suptitle('')\n",
    "ax1.imshow(image_sprat[0].permute(1, 2, 0))\n",
    "ax2.imshow(image_bream[0].permute(1, 2, 0))\n",
    "ax3.imshow(image_shrimp[0].permute(1, 2, 0))\n",
    "ax4.imshow(image_mullet[0].permute(1, 2, 0))\n",
    "ax5.imshow(image_trout[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(filename, data):\n",
    "    '''\n",
    "    pickles data into a file\n",
    "    '''\n",
    "    pickle.dump(data, open(filename, 'wb'))\n",
    "\n",
    "train_filename = 'train_data.sav'\n",
    "save_file(train_filename, dataset)\n",
    "\n",
    "test_filename = 'test_data.sav'\n",
    "save_file(test_filename, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Discussion. (10 points)\n",
    "\n",
    "* Is the dataset balanced?\n",
    "\n",
    "* Can you think of 3 ways to make the dataset balanced if it is not?\n",
    "\n",
    "* Is the dataset already pre-processed? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADD YOUR RESPONSE HERE ####\n",
    "- As you can see from the distribution in part 2.1, there is an uneven distribution of each class within the train and test sets. The numbers are close (within the range 787-811 between min and max), so it is relatively well distributed, but not perfectly distributed. If it was a perfectly balanced dataset, we would see exactly 800 of each in the train set, and 200 of each in the test set.\n",
    "- Three possible ways to  make the dataset balanced are:\n",
    "    - Use a larger dataset. If we have more than 5000 data points, the split into train and test is more likely to result in a more even distribution. For example, if we split 50,000 data points, the average will lie much closer to 8,000. \n",
    "    - Split the individual classes before combining them. For example, we can split all 1000 trout pictures into 800 train and 200 test, before combining the 5 train classes and 5 test classes. This way, we are guaranteed an exactly perfect distribution of each class in the train and test set. This method would work better for smaller sample sizes such as ours.\n",
    "    - Another simple solution is to use scikit-learn's _train_test_split_ function, which should automatically divide them into an even distribution.\n",
    "- The dataset is now pre-processed, because we have made every data point the same size image (128x128x3). I have also chosen to return them as tensors in \\_\\_getitem\\_\\_()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Multiclass classification. (55 points)\n",
    "In this section we will try to make a multiclass classifier to determine the species of the fish.\n",
    "\n",
    "### Step 3.1: Define the model. (15 points)\n",
    "\n",
    "Design a neural network which consists of a number of convolutional layers and a few fully connected ones at the end.\n",
    "\n",
    "The exact architecture is up to you but you do NOT need to create something complicated. For example, you could design a LeNet insprired network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open(\"train_data.sav\", \"rb\"))\n",
    "test_set = pickle.load(open(\"test_data.sav\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, output_dims = 1):\n",
    "        super(Net, self).__init__()\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        '''\n",
    "        Structure: \n",
    "          input   -- C1 feature maps -- S2 fmaps  -- C3 fmaps -- S4 fmaps -- \n",
    "        128x128x3 --   124x124x6   -- 62x62x6 -- ?x?x3x?  -- ?x?x3x?  -- \n",
    "               5x5 conv            pooling      5x5 conv    pooling     \n",
    "        '''\n",
    "        self.conv1 = nn.Conv2d(3,6,5)  # output: 124x124x6\n",
    "        self.relu1 = nn.ReLU()         # activation function\n",
    "        self.pool1 = nn.MaxPool2d(2)   # 2 stride: 62x62x6\n",
    "        self.conv2 = nn.Conv2d(6,16,5) # output: 58x58x16\n",
    "        self.relu2 = nn.ReLU()         # activation function\n",
    "        self.pool2 = nn.MaxPool2d(2)   # pool : 29x29x16\n",
    "        self.fc1 = nn.Linear(13456,120)  # fully connected\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120,84) # fully connected\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84,output_dims) # last output has output_dims \n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward propagation\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        h = self.conv1(x)\n",
    "        h = self.relu1(h)\n",
    "        h = self.pool1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.relu2(h)\n",
    "        h = self.pool2(h)\n",
    "        h = h.view(h.shape[0], -1) # to get [batch_size, num_features]\n",
    "        h = self.fc1(h)\n",
    "        h = self.relu3(h)\n",
    "        h = self.fc2(h)\n",
    "        h = self.relu4(h)\n",
    "        h = self.fc3(h)\n",
    "        y = self.relu5(h)\n",
    "        return y\n",
    "\n",
    "# Since most of you use laptops, you may use CPU for training.\n",
    "# If you have a good GPU, you can set this to 'gpu'.\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Define the training parameters. (10 points)\n",
    "\n",
    "- Loss function\n",
    "- Optimizer\n",
    "- Learning Rate\n",
    "- Number of iterations\n",
    "- Batch Size\n",
    "- Other relevant hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Network\n",
    "model = Net(5).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimiser and learning rate\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "# Number of iterations for training\n",
    "epochs = 15\n",
    "\n",
    "# Training batch size\n",
    "train_batch_size = 16\n",
    "\n",
    "# Based on the FishDataset, use the PyTorch DataLoader to load the data during model training\n",
    "train_dataset = dataset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = train_batch_size)\n",
    "test_dataset = test_set\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3: Train the model. (15 points)\n",
    "\n",
    "Complete the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "### Visualizing the shapes and sizes of the dataset ###\n",
    "print(dataset.__getitem__(0)[0].shape)\n",
    "print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                             | 1/15 [00:17<04:00, 17.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1: training loss = 1.6045 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|                                                                        | 2/15 [00:34<03:47, 17.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 2: training loss = 1.5107 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|                                                                  | 3/15 [00:53<03:38, 18.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 3: training loss = 1.0750 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|                                                            | 4/15 [01:13<03:23, 18.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 4: training loss = 0.8807 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|                                                       | 5/15 [01:31<03:06, 18.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 5: training loss = 0.6506 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|                                                 | 6/15 [01:50<02:48, 18.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 6: training loss = 0.4591 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|                                            | 7/15 [02:09<02:31, 18.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 7: training loss = 0.3101 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|                                      | 8/15 [02:28<02:12, 18.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 8: training loss = 0.2220 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|                                 | 9/15 [02:47<01:53, 18.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 9: training loss = 0.1979 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|                           | 10/15 [03:06<01:34, 18.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 10: training loss = 0.1802 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|                     | 11/15 [03:25<01:15, 18.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 11: training loss = 0.1795 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|                | 12/15 [03:44<00:56, 18.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 12: training loss = 0.0983 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|           | 13/15 [04:03<00:37, 18.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 13: training loss = 0.0777 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|     | 14/15 [04:22<00:18, 18.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 14: training loss = 0.0714 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [04:41<00:00, 18.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 15: training loss = 0.0445 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    loss_curve = []\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        # Get a batch of training data and train the model\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_curve += [loss.item()]\n",
    "    print('--- Iteration {0}: training loss = {1:.4f} ---'.format(epoch + 1, np.array(loss_curve).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.4: Deploy the trained model onto the test set. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaixuan Khoo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\serialization.py:359: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    }
   ],
   "source": [
    "model_save_path = './model_train2.pth'\n",
    "torch.save(model, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=13456, out_features=120, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (fc3): Linear(in_features=84, out_features=5, bias=True)\n",
       "  (relu5): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = './model_train2.pth'\n",
    "model = torch.load(model_save_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 96.0 %\n"
     ]
    }
   ],
   "source": [
    "# Deploy the model\n",
    "#### ADD YOUR CODE HERE ####\n",
    "## code is combined with accuracy below\n",
    "correct = 0\n",
    "total = 0\n",
    "# modifying these variables for later\n",
    "predicted = 0 \n",
    "images, labels = 0, 0\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 1000 test images: {100. * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.5: Evaluate the performance of the model and visualize the confusion matrix. (5 points)\n",
    "\n",
    "You can use sklearns related function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Black Sea Sprat', 1: 'Gilt-Head Bream', 2: 'Shrimp', 3: 'Striped Red Mullet', 4: 'Trout'}\n",
      "[[182   1   0   6   0]\n",
      " [  0 184   0   3   4]\n",
      " [  0   2 207   3   1]\n",
      " [  0   7   1 196   0]\n",
      " [  0   4   0   0 199]]\n"
     ]
    }
   ],
   "source": [
    "#### ADD YOUR CODE HERE ####\n",
    "classes = {v: k for k, v in Multiclass_labels_correspondances.items()} # invert the values and keys\n",
    "\n",
    "y_true = []\n",
    "for i in range(labels.size()[0]):\n",
    "    y_true.append(labels[i].item())\n",
    "y_pred = []\n",
    "for i in range(predicted.size()[0]):\n",
    "    y_pred.append(predicted[i].item())\n",
    "\n",
    "print(classes)\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Finetune your classifier. (15 points)\n",
    "\n",
    "In the previous section, you have built a pretty good classifier for certain species of fish. Now we are going to use this trained classifier and adapt it to classify a new set of species:\n",
    "\n",
    "    'Hourse Mackerel\n",
    "    'Red Mullet',\n",
    "    'Red Sea Bream'\n",
    "    'Sea Bass'\n",
    "\n",
    "### Step 4.1: Set up the data for new species. (2 points)\n",
    "Overwrite the labels correspondances so they only incude the new classes and regenerate the datasets and dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "# was having an error loading some of the images in this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Multiclass_labels_correspondances ={\n",
    "    'Hourse Mackerel': 0,\n",
    "    'Red Mullet': 1,\n",
    "    'Red Sea Bream': 2,\n",
    "    'Sea Bass': 3}\n",
    "\n",
    "LENDATA = 4000\n",
    "idxs_train,idxs_test = split_train_test(LENDATA, 0.8)\n",
    "img_path = './Fish_Dataset'\n",
    "# Dataloaders\n",
    "#### ADD YOUR CODE HERE ####\n",
    "dataset = FishDataset(img_path, idxs_train, idxs_test, None, img_size=128, train=True)\n",
    "test_set = FishDataset(img_path, idxs_train, idxs_test, None, img_size=128, train=False)\n",
    "train_dataset = dataset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 16)\n",
    "test_dataset = test_set\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Freeze the weights of all previous layers of the network except the last layer. (5 points)\n",
    "\n",
    "You can freeze them by setting the gradient requirements to ```False```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def freeze_till_last(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "freeze_till_last(model)\n",
    "# Modify the last layer. This layer is not freezed.\n",
    "#### ADD YOUR CODE HERE ####\n",
    "# unfreezing last layer\n",
    "for param in model.fc3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.relu5.parameters():\n",
    "    param.requires_grad = True\n",
    "model.fc3 = nn.Linear(84,4)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimiser and learning rate\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9)\n",
    "\n",
    "# Number of iterations for training\n",
    "epochs = 15\n",
    "\n",
    "# Training batch size\n",
    "train_batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3: Train and test your finetuned model. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                             | 1/15 [00:07<01:41,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1: training loss = 0.6078 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|                                                                        | 2/15 [00:14<01:33,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 2: training loss = 0.6053 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|                                                                  | 3/15 [00:21<01:26,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 3: training loss = 0.6029 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|                                                            | 4/15 [00:28<01:19,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 4: training loss = 0.6007 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|                                                       | 5/15 [00:36<01:13,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 5: training loss = 0.5985 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|                                                 | 6/15 [00:43<01:06,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 6: training loss = 0.5964 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|                                            | 7/15 [00:51<00:59,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 7: training loss = 0.5944 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|                                      | 8/15 [00:59<00:52,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 8: training loss = 0.5924 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|                                 | 9/15 [01:06<00:44,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 9: training loss = 0.5905 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|                           | 10/15 [01:13<00:37,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 10: training loss = 0.5886 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|                     | 11/15 [01:21<00:29,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 11: training loss = 0.5869 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|                | 12/15 [01:28<00:22,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 12: training loss = 0.5852 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|           | 13/15 [01:36<00:14,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 13: training loss = 0.5834 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|     | 14/15 [01:43<00:07,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 14: training loss = 0.5818 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [01:51<00:00,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 15: training loss = 0.5802 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Finetune the model\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    loss_curve = []\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        # Get a batch of training data and train the model\n",
    "        #### ADD YOUR CODE HERE ####\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_curve += [loss.item()]\n",
    "    print('--- Iteration {0}: training loss = {1:.4f} ---'.format(epoch + 1, np.array(loss_curve).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 74.0 %\n",
      "{0: 'Hourse Mackerel', 1: 'Red Mullet', 2: 'Red Sea Bream', 3: 'Sea Bass'}\n",
      "[[138  24   7  19]\n",
      " [ 16 163   7   4]\n",
      " [  4  24 170   9]\n",
      " [ 41  42   4 128]]\n"
     ]
    }
   ],
   "source": [
    "# Deploy the model on the test set\n",
    "#### ADD YOUR CODE HERE ####\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# modifying these variables for later\n",
    "predicted = 0 \n",
    "images, labels = 0, 0\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 1000 test images: {100.0 * correct // total} %')\n",
    "\n",
    "# Evaluate the performance\n",
    "#### ADD YOUR CODE HERE ####\n",
    "classes = {v: k for k, v in Multiclass_labels_correspondances.items()} # invert the values and keys\n",
    "\n",
    "y_true = []\n",
    "for i in range(labels.size()[0]):\n",
    "    y_true.append(labels[i].item())\n",
    "y_pred = []\n",
    "for i in range(predicted.size()[0]):\n",
    "    y_pred.append(predicted[i].item())\n",
    "\n",
    "print(classes)\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaixuan Khoo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\serialization.py:359: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    }
   ],
   "source": [
    "model_save_path = './model_train_finetune.pth'\n",
    "torch.save(model, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=13456, out_features=120, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (fc3): Linear(in_features=84, out_features=4, bias=True)\n",
       "  (relu5): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(model_save_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempting to unfreeeze more layers to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_till_last(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "freeze_till_last(model)\n",
    "# unfreezing more layers\n",
    "for param in model.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.relu4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.fc3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.relu5.parameters():\n",
    "    param.requires_grad = True\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimiser and learning rate\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9)\n",
    "# Number of iterations for training\n",
    "epochs = 15\n",
    "# Training batch size\n",
    "train_batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                             | 1/15 [00:07<01:46,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1: training loss = 0.3823 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|                                                                        | 2/15 [00:15<01:38,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 2: training loss = 0.3748 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|                                                                  | 3/15 [00:22<01:31,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 3: training loss = 0.3678 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|                                                            | 4/15 [00:30<01:25,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 4: training loss = 0.3611 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|                                                       | 5/15 [00:39<01:20,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 5: training loss = 0.3548 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|                                                 | 6/15 [00:47<01:12,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 6: training loss = 0.3487 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|                                            | 7/15 [00:55<01:05,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 7: training loss = 0.3430 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|                                      | 8/15 [01:03<00:57,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 8: training loss = 0.3375 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|                                 | 9/15 [01:12<00:49,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 9: training loss = 0.3321 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|                           | 10/15 [01:20<00:41,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 10: training loss = 0.3270 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|                     | 11/15 [01:28<00:33,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 11: training loss = 0.3220 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|                | 12/15 [01:37<00:24,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 12: training loss = 0.3172 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|           | 13/15 [01:45<00:16,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 13: training loss = 0.3128 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|     | 14/15 [01:53<00:08,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 14: training loss = 0.3086 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [02:02<00:00,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 15: training loss = 0.3045 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Finetune the model\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    loss_curve = []\n",
    "    for images, labels in train_dataloader:\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "        loss_curve += [loss.item()]\n",
    "    print('--- Iteration {0}: training loss = {1:.4f} ---'.format(epoch + 1, np.array(loss_curve).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 85.0 %\n",
      "{0: 'Hourse Mackerel', 1: 'Red Mullet', 2: 'Red Sea Bream', 3: 'Sea Bass'}\n",
      "[[165   7   5  11]\n",
      " [  7 181   1   1]\n",
      " [  3  20 178   6]\n",
      " [ 17  29   6 163]]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# modifying these variables for later\n",
    "predicted = 0 \n",
    "images, labels = 0, 0\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy of the network on the 1000 test images: {100.0 * correct // total} %')\n",
    "\n",
    "classes = {v: k for k, v in Multiclass_labels_correspondances.items()} # invert the values and keys\n",
    "y_true = []\n",
    "for i in range(labels.size()[0]):\n",
    "    y_true.append(labels[i].item())\n",
    "y_pred = []\n",
    "for i in range(predicted.size()[0]):\n",
    "    y_pred.append(predicted[i].item())\n",
    "\n",
    "print(classes)\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.4: Did finetuning work? Why did we freeze the first few layers? (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning\n",
    "Finetuning in the context of this coursework is a form of <b>Transfer Learning</b>, where we are taking a model that has been trained previously on a different set of images. We take this previously trained model, freeze all the weights of the network, except for the last fully connected layer. Then, we train the last layer of the model on a new set of data (here, the other 4 types of fish). \n",
    "\n",
    "The accuracy of the finetuned model was 74%, which is lower than the 96% for the original set of data. However, 74% is still a relatively good result (at least it performs much better than random sampling which would be 25% or 1 in 4). This also has the benefit of taking significantly shorter time to train (~8 seconds per epoch, as opposed to the 18 seconds for the original model, because we only have 1 layer in which we need to backpropagate. This means we can make the learning rate much smaller as well.\n",
    "\n",
    "### Evaluation and attempted solutions\n",
    "The confusion matrix for the original network and test set (96%):\n",
    "$$\\begin{bmatrix} 182 & 1 & 0 & 6 & 0 \\\\ 0 & 184 & 0 & 3 & 4 \\\\ 0 & 2 & 207 & 3 & 1 \\\\ 0 & 7 & 1 & 196 & 0 \\\\ 0 & 4 & 0 & 0 & 199 \\end{bmatrix}$$\n",
    "\n",
    "The confusion matrix for the finetuned network was (74%):\n",
    "$$\\begin{bmatrix} 138 & 24 & 7 & 19 \\\\ 16 & 163 & 7 & 4 \\\\ 4 & 24 & 170 & 9 \\\\ 41 & 42 & 4 & 128 \\end{bmatrix}$$\n",
    "\n",
    "The reason we have a much lower accuracy for the finetuned network is likely due to overfitting of the original dataset, which likely happens in the earlier neurons in the network, which we have frozen. The LeNet5-inspired network has quite a few layers, which makes overfitting on the original data quite possible. This would explain why the original set had such a high accuracy, while the finetuned network had a lower accuracy.\n",
    "\n",
    "In order to improve this accuracy, I have tried unfreezing the second-to-last layer as well, and evaluating that performance (see above). When I did this, the accuracy of the new finetuned network was (85%), and the confusion matrix was:\n",
    "$$\\begin{bmatrix} 165 & 7 & 5 & 11 \\\\ 7 & 181 & 1 & 1 \\\\ 3 & 20 & 178 & 6 \\\\ 17 & 29 & 6 & 163 \\end{bmatrix}$$\n",
    "\n",
    "We can see that this has dramatically improved the accuracy of our Transfer Learning model, further indicating that the original dataset was overfitted.\n",
    "\n",
    "### Other ways of reducing overfitting\n",
    "We have demonstrated above that the data is being overfitted. Here are my suggestions to decrease the amount of overfitting and thus improve our transfer learning model:\n",
    "\n",
    "<center><h4> Reducing complexity of the model / Dropouts </h4></center> \n",
    "\n",
    "One method of preventing overfitting of the dataset is to make the neural network simpler. The LeNet5 model may be too complex for transfer learning. The example code I would suggest to simplify the neural network is as follows:\n",
    "\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, output_dims = 1):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)  \n",
    "        self.pool1 = nn.MaxPool2d(2)   \n",
    "        self.conv2 = nn.Conv2d(6,16,5) \n",
    "        self.pool2 = nn.MaxPool2d(2)   \n",
    "        self.fc1 = nn.Linear(13456,120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout() # dropout!\n",
    "        self.fc2 = nn.Linear(120,output_dims) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.pool1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.pool2(h)\n",
    "        h = h.view(h.shape[0], -1)\n",
    "        h = self.fc1(h)\n",
    "        h = self.relu(h)\n",
    "        h = self.fc2(h)\n",
    "        h = self.dropout(h)\n",
    "        return y\n",
    "```\n",
    "Here, the number of fully connected layers has been decreased, and we have introduced dropout in the linear layer (see comment in the code above). Removing layers could be a good way of preventing overfitting, as it prevents the model from becoming too complex. Here, introducing Dropout can also help to prevent overfitting, by preventing \"over-reliance\" on a few of its inputs. This could be a simple yet effective way of making the finetuning better. \n",
    "\n",
    "<center><h4> K-Fold Cross Validation </h4></center> \n",
    "\n",
    "Another method that could be done is to use cross validation in the training.\n",
    "This would involve:\n",
    " - Splitting the training set into K-folds (e.g. 5 sets: 4 for training and 1 for testing)\n",
    " - Training the model\n",
    " - Iterating over the folds for validation\n",
    "\n",
    "<center><h4> Regularization </h4></center> \n",
    "\n",
    "Regularization is a method well-known in machine learning to prevent overfitting of our data. To do so, we would have to:\n",
    " - Define a regularization penalty $R(W)$\n",
    "     - e.g. weight decay\n",
    "     - $R(W) = \\sum_{i} \\sum_{j} W^2$\n",
    " - Operate in on our weight matrix at each step of the network\n",
    " - This favours small weights over large weights, which will improve the ability of our model to generalize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
